2025-05-18 21:10:45,713 - INFO - âœ… meta.pkl successfully saved.
2025-05-18 21:10:59,239 - INFO - âœ… Loaded 46801 training and 5201 validation samples.
2025-05-18 21:10:59,239 - INFO - Sample tokenized data: [21017, 46486, 25, 198, 23318, 1115, 9040, 329, 10589, 5448, 13, 198, 198, 21017, 18261, 25, 198, 16, 13, 47659]
2025-05-18 21:10:59,240 - INFO - Sample decoded: ### Instruction:
Give three tips for staying healthy.

### Response:
1.Eat
2025-05-18 21:10:59,599 - INFO - âœ… Model weights initialized within GPT class.
2025-05-18 21:10:59,599 - INFO - Model config: vocab_size=50257, block_size=128, n_layer=4, n_head=4, n_embd=128
2025-05-18 21:11:01,490 - WARNING - Failed to load checkpoint: Error(s) in loading state_dict for GPT:
	Missing key(s) in state_dict: "layers.0.sa.qkv.weight", "layers.0.sa.qkv.bias", "layers.0.sa.proj.weight", "layers.0.sa.proj.bias", "layers.0.ffwd.net.0.weight", "layers.0.ffwd.net.0.bias", "layers.0.ffwd.net.2.weight", "layers.0.ffwd.net.2.bias", "layers.0.ln1.weight", "layers.0.ln1.bias", "layers.0.ln2.weight", "layers.0.ln2.bias", "layers.1.sa.qkv.weight", "layers.1.sa.qkv.bias", "layers.1.sa.proj.weight", "layers.1.sa.proj.bias", "layers.1.ffwd.net.0.weight", "layers.1.ffwd.net.0.bias", "layers.1.ffwd.net.2.weight", "layers.1.ffwd.net.2.bias", "layers.1.ln1.weight", "layers.1.ln1.bias", "layers.1.ln2.weight", "layers.1.ln2.bias", "layers.2.sa.qkv.weight", "layers.2.sa.qkv.bias", "layers.2.sa.proj.weight", "layers.2.sa.proj.bias", "layers.2.ffwd.net.0.weight", "layers.2.ffwd.net.0.bias", "layers.2.ffwd.net.2.weight", "layers.2.ffwd.net.2.bias", "layers.2.ln1.weight", "layers.2.ln1.bias", "layers.2.ln2.weight", "layers.2.ln2.bias", "layers.3.sa.qkv.weight", "layers.3.sa.qkv.bias", "layers.3.sa.proj.weight", "layers.3.sa.proj.bias", "layers.3.ffwd.net.0.weight", "layers.3.ffwd.net.0.bias", "layers.3.ffwd.net.2.weight", "layers.3.ffwd.net.2.bias", "layers.3.ln1.weight", "layers.3.ln1.bias", "layers.3.ln2.weight", "layers.3.ln2.bias", "ln_f.weight", "ln_f.bias". 
2025-05-18 21:11:06,828 - INFO - ğŸ” iter 0: train loss = 12.3883
2025-05-18 21:11:07,015 - INFO - âœ… step 0: val loss = 1.0446
2025-05-18 21:11:07,016 - INFO - ğŸ§  Sample: ### Instruction:
Given two topics, find out which is more relevant to the query.

### Response:
Anxiety Disorder is more relevant to the query than Alzheimer's Disease.
2025-05-18 21:11:07,017 - INFO - State dict keys to save: ['token_embedding_table.weight', 'position_embedding_table.weight', 'layers.0.sa.qkv.weight', 'layers.0.sa.qkv.bias', 'layers.0.sa.proj.weight', 'layers.0.sa.proj.bias', 'layers.0.ffwd.net.0.weight', 'layers.0.ffwd.net.0.bias', 'layers.0.ffwd.net.2.weight', 'layers.0.ffwd.net.2.bias']... (total 54 keys)
2025-05-18 21:11:07,500 - INFO - ğŸ“¦ Checkpoint saved at out/ckpt_20250518_211101.pt
2025-05-18 21:11:07,916 - INFO - ğŸŒŸ Best model saved at out/best_model.pt
2025-05-18 21:18:40,415 - INFO - ğŸ” iter 100: train loss = 0.6826
2025-05-18 22:57:17,876 - INFO - ğŸ” iter 200: train loss = 0.5939
2025-05-18 23:44:09,050 - INFO - ğŸ” iter 300: train loss = 0.4709
2025-05-19 01:01:16,092 - INFO - ğŸ” iter 400: train loss = 0.4704
2025-05-19 06:20:40,444 - INFO - ğŸ” iter 500: train loss = 0.3633
2025-05-19 06:20:40,597 - INFO - âœ… step 500: val loss = 0.0496
2025-05-19 06:20:40,600 - INFO - ğŸ§  Sample: ### Instruction:
Fill in the blank "Computers can help us to _____ information more efficiently."

### Response:
Computers can help us to organize and analyze information more efficiently.
2025-05-19 06:20:40,601 - INFO - State dict keys to save: ['token_embedding_table.weight', 'position_embedding_table.weight', 'layers.0.sa.qkv.weight', 'layers.0.sa.qkv.bias', 'layers.0.sa.proj.weight', 'layers.0.sa.proj.bias', 'layers.0.ffwd.net.0.weight', 'layers.0.ffwd.net.0.bias', 'layers.0.ffwd.net.2.weight', 'layers.0.ffwd.net.2.bias']... (total 54 keys)
2025-05-19 06:20:40,797 - INFO - ğŸ“¦ Checkpoint saved at out/ckpt_20250518_211101.pt
2025-05-19 06:20:41,012 - INFO - ğŸŒŸ Best model saved at out/best_model.pt
2025-05-19 07:00:12,854 - INFO - ğŸ” iter 600: train loss = 0.2568
2025-05-19 07:47:12,415 - INFO - ğŸ” iter 700: train loss = 0.2381
2025-05-19 09:03:02,626 - INFO - ğŸ” iter 800: train loss = 0.2892
2025-05-19 10:06:07,208 - INFO - ğŸ” iter 900: train loss = 0.3842
2025-05-19 13:01:31,929 - INFO - ğŸ” iter 1000: train loss = 0.3385
2025-05-19 13:01:32,073 - INFO - âœ… step 1000: val loss = 0.0441
2025-05-19 13:01:32,084 - INFO - ğŸ§  Sample: ### Instruction:
Given a scenario, generate a dialogue between two characters of your choice

### Response:
Person A: Hey, it's been so long since I last saw you!
Person B: I know! It's been ages! It's so good to see you again! 
Person A: I'm so happy to see you too! How have you been?
Person B: I'm doing great! How about you? What have you been up to?
2025-05-19 13:01:32,085 - INFO - State dict keys to save: ['token_embedding_table.weight', 'position_embedding_table.weight', 'layers.0.sa.qkv.weight', 'layers.0.sa.qkv.bias', 'layers.0.sa.proj.weight', 'layers.0.sa.proj.bias', 'layers.0.ffwd.net.0.weight', 'layers.0.ffwd.net.0.bias', 'layers.0.ffwd.net.2.weight', 'layers.0.ffwd.net.2.bias']... (total 54 keys)
2025-05-19 13:01:32,304 - INFO - ğŸ“¦ Checkpoint saved at out/ckpt_20250518_211101.pt
2025-05-19 13:01:32,513 - INFO - ğŸŒŸ Best model saved at out/best_model.pt
2025-05-19 15:45:32,606 - INFO - ğŸ” iter 1100: train loss = 0.1967
2025-05-19 16:09:56,808 - INFO - ğŸ” iter 1200: train loss = 0.4566
2025-05-19 16:15:57,484 - INFO - ğŸ” iter 1300: train loss = 0.2756
2025-05-19 16:21:47,181 - INFO - ğŸ” iter 1400: train loss = 0.2688
2025-05-19 16:27:25,945 - INFO - ğŸ” iter 1500: train loss = 0.1776
2025-05-19 16:27:26,072 - INFO - âœ… step 1500: val loss = 0.0025
2025-05-19 16:27:26,084 - INFO - ğŸ§  Sample: ### Instruction:
Express a birthday wish for someone turning 19 years old.

### Response:
Happy 19th birthday! May this year be filled with joy, laughter and amazing experiences.
2025-05-19 16:27:26,089 - INFO - State dict keys to save: ['token_embedding_table.weight', 'position_embedding_table.weight', 'layers.0.sa.qkv.weight', 'layers.0.sa.qkv.bias', 'layers.0.sa.proj.weight', 'layers.0.sa.proj.bias', 'layers.0.ffwd.net.0.weight', 'layers.0.ffwd.net.0.bias', 'layers.0.ffwd.net.2.weight', 'layers.0.ffwd.net.2.bias']... (total 54 keys)
2025-05-19 16:27:26,306 - INFO - ğŸ“¦ Checkpoint saved at out/ckpt_20250518_211101.pt
2025-05-19 16:27:26,499 - INFO - ğŸŒŸ Best model saved at out/best_model.pt
2025-05-19 16:33:15,666 - INFO - ğŸ” iter 1600: train loss = 0.2654
2025-05-19 16:39:09,475 - INFO - ğŸ” iter 1700: train loss = 0.5274
2025-05-19 16:45:04,383 - INFO - ğŸ” iter 1800: train loss = 0.2126
2025-05-19 16:51:26,303 - INFO - ğŸ” iter 1900: train loss = 0.2974
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
